{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f20b8235-1157-40d9-b7f1-549aad19c3df",
   "metadata": {},
   "source": [
    "# Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e416ed-7930-408d-ac9a-03adffadf0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from utils import display_images,display_image\n",
    "import imutils\n",
    "\n",
    "img=cv2.imread(\"images/lena.jfif\")\n",
    "rotated = imutils.rotate_bound(img,45)\n",
    "cv2.imshow(\"Rotated by 45 Degrees\", rotated)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ab3dd1-4cfb-44f0-a8f6-d47b276f0697",
   "metadata": {},
   "source": [
    "# Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b76bd98-43be-4ad3-adca-cf781f9a1dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('images/flower.jfif')\n",
    "\n",
    "# Convert the image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Create a binary mask where black pixels are 0 and other pixels are 255\n",
    "_, binary_mask = cv2.threshold(gray_image, 20, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# Use morphological operations to clean up the mask\n",
    "kernel = np.ones((5, 5), np.uint8)\n",
    "clean_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "# Convert the cleaned mask to a 3-channel image\n",
    "mask_3channel = cv2.cvtColor(clean_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Apply the cleaned mask to the image to get the foreground (flower)\n",
    "foreground = cv2.bitwise_and(image, mask_3channel)\n",
    "\n",
    "# Create a new background (if needed)\n",
    "background = np.full_like(image, 255)  # white background, or any other color/image\n",
    "\n",
    "# Invert the cleaned mask for the background\n",
    "inverse_mask = cv2.bitwise_not(clean_mask)\n",
    "inverse_mask_3channel = cv2.cvtColor(inverse_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "# Apply the inverse mask to the new background\n",
    "background = cv2.bitwise_and(background, inverse_mask_3channel)\n",
    "\n",
    "# Combine the foreground and background\n",
    "result = cv2.add(foreground, background)\n",
    "\n",
    "# Save and display the result\n",
    "cv2.imwrite('result.png', result)\n",
    "cv2.imshow('remove', result)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bed53c0-e595-4bd7-80d4-c2d077185ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "def mouse(event,x,y,flags,params):\n",
    "    if event ==cv.EVENT_LBUTTONDOWN:\n",
    "        print(x,\",\",y)\n",
    "        cv.imshow(\"bee\",img)\n",
    "\n",
    "img=cv.imread(\"images/native-bee.png\")\n",
    "cv.imshow(\"bee\",img)\n",
    "cv.setMouseCallback(\"bee\",mouse)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfc064c-88df-4806-9a6a-27e7d3c3bb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "# Load the images\n",
    "result\n",
    "bee_img = cv.imread(\"images/native-bee.png\")\n",
    "\n",
    "# Coordinates for placing the flower image\n",
    "points = np.array([[79,94], [167, 81], [171, 136], [95, 143]])\n",
    "\n",
    "# Check if the images were loaded successfully\n",
    "\n",
    "    # Step 1: Determine the bounding box of the points\n",
    "x, y, w, h = cv.boundingRect(points)\n",
    "    \n",
    "    # Resize the flower image to fit the bounding box\n",
    "flower_resized = cv.resize(result, (w, h))\n",
    "    \n",
    "    # Step 2: Convert the resized flower image to grayscale\n",
    "flower_gray = cv.cvtColor(flower_resized, cv.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply a binary threshold to create a mask\n",
    "_, mask = cv.threshold(flower_gray, 240, 255, cv.THRESH_BINARY_INV)\n",
    "    \n",
    "    # Optionally, use morphological operations to clean up the mask\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Create the inverse mask\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "    \n",
    "    # Step 3: Define the region of interest (ROI) in the bee image\n",
    "roi = bee_img[y:y+h, x:x+w]\n",
    "    \n",
    "    # Use the inverse mask to black out the area of the flower in the bee image\n",
    "bee_bg = cv.bitwise_and(roi, roi, mask=mask_inv)\n",
    "    \n",
    "    # Take only the region of the flower from the flower image using the mask\n",
    "flower_fg = cv.bitwise_and(flower_resized, flower_resized, mask=mask)\n",
    "    \n",
    "    # Combine the two images\n",
    "combined = cv.add(bee_bg, flower_fg)\n",
    "    \n",
    "    # Place the combined image back into the original bee image\n",
    "bee_img[y:y+h, x:x+w] = combined\n",
    "    \n",
    "    # Display the result\n",
    "\n",
    "cv.imshow(\"Combined Image\", bee_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572706c1-b66b-4087-acda-d638f085b91b",
   "metadata": {},
   "source": [
    "# Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f67f6eb-5462-4c26-aa42-acddf48ef29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def random_center_crop(image, min_crop_ratio, max_crop_ratio):\n",
    "\n",
    "    if not (0.0 <= min_crop_ratio <= 1.0) or not (0.0 <= max_crop_ratio <= 1.0):\n",
    "        raise ValueError(\"Crop ratios must be between 0.0 and 1.0\")\n",
    "    if min_crop_ratio > max_crop_ratio:\n",
    "        raise ValueError(\"min_crop_ratio must be less than or equal to max_crop_ratio\")\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "    \n",
    "    # Randomly choose the crop ratio\n",
    "    crop_ratio = random.uniform(min_crop_ratio, max_crop_ratio)\n",
    "    new_height, new_width = int(height * crop_ratio), int(width * crop_ratio)\n",
    "    \n",
    "    # Calculate cropping box coordinates\n",
    "    center_y, center_x = height // 2, width // 2\n",
    "    y1 = max(center_y - new_height // 2, 0)\n",
    "    y2 = min(center_y + new_height // 2, height)\n",
    "    x1 = max(center_x - new_width // 2, 0)\n",
    "    x2 = min(center_x + new_width // 2, width)\n",
    "    \n",
    "\n",
    "    cropped_image = image[y1:y2, x1:x2]\n",
    "    \n",
    "\n",
    "    resized_image = cv.resize(cropped_image, (width, height))\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "\n",
    "\n",
    "img = cv.imread(\"images/flower.jfif\")\n",
    "\n",
    "if img is None:\n",
    "    raise FileNotFoundError(f\"Image not found at path: {img_path}\")\n",
    "\n",
    "cropped_img = random_center_crop(img, 0.5, 0.75)\n",
    "\n",
    "\n",
    "cv.imshow('Cropped Image', cropped_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290dd2e-cd90-467d-af3e-2a7ff5138c68",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c09160-9315-4761-8ce2-f08bbad8055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "\n",
    "def add_salt_and_pepper_noise(image, salt_prob, pepper_prob):\n",
    "\n",
    "    output = np.copy(image)\n",
    "    total_pixels = image.size\n",
    "    num_salt = int(total_pixels * salt_prob)\n",
    "    num_pepper = int(total_pixels * pepper_prob)\n",
    "    \n",
    "    # Add salt noise (white pixels)\n",
    "    salt_coords = [np.random.randint(0, i-1, num_salt) for i in image.shape]\n",
    "    output[salt_coords[0], salt_coords[1]] = 255\n",
    "    \n",
    "    # Add pepper noise (black pixels)\n",
    "    pepper_coords = [np.random.randint(0, i-1, num_pepper) for i in image.shape]\n",
    "    output[pepper_coords[0], pepper_coords[1]] = 0\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "img = cv.imread(\"images/lena.jfif\")\n",
    "\n",
    "noisy_img = add_salt_and_pepper_noise(img, 0.01, 0.01)\n",
    "\n",
    "# Display the noisy image\n",
    "cv.imshow('Noisy Image', noisy_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
